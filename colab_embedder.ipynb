{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# AGN Health Q&A Embedder - Google Colab\n",
    "\n",
    "Notebook ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á vector embeddings ‡πÅ‡∏•‡∏∞ MongoDB Atlas Vector Search index\n",
    "\n",
    "## ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:\n",
    "1. ‡∏£‡∏±‡∏ô Cell ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á dependencies\n",
    "2. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ environment variables\n",
    "3. ‡∏£‡∏±‡∏ô embedder\n",
    "4. ‡∏™‡∏£‡πâ‡∏≤‡∏á vector search index\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install"
   },
   "source": [
    "## 1. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Python packages\n",
    "!pip install sentence-transformers pymongo torch transformers python-dotenv -q\n",
    "\n",
    "print(\"‚úÖ Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## 2. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤ Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config-vars"
   },
   "outputs": [],
   "source": [
    "# MongoDB Configuration\n",
    "MONGODB_URL = \"mongodb+srv://natthapiw_db_user:afOJe2MrgMDsmm6k@cluster0.skadipr.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "MONGODB_DATABASE = \"agn\"\n",
    "MONGODB_COLLECTION = \"qa\"\n",
    "\n",
    "# Embedding Configuration\n",
    "EMBEDDING_MODEL = \"BAAI/bge-m3\"\n",
    "EMBEDDING_DIMENSION = 1024\n",
    "\n",
    "# Vector Index Configuration\n",
    "VECTOR_INDEX_NAME = \"vector_index\"\n",
    "\n",
    "print(\"‚úÖ Configuration set successfully!\")\n",
    "print(f\"ü§ñ Embedding Model: {EMBEDDING_MODEL}\")\n",
    "print(f\"üìè Embedding Dimension: {EMBEDDING_DIMENSION}\")\n",
    "print(f\"üóÑÔ∏è  Database: {MONGODB_DATABASE}.{MONGODB_COLLECTION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "check-data"
   },
   "source": [
    "## 3. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-mongodb"
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ MongoDB\n",
    "client = MongoClient(MONGODB_URL)\n",
    "db = client[MONGODB_DATABASE]\n",
    "collection = db[MONGODB_COLLECTION]\n",
    "\n",
    "# ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "total_docs = collection.count_documents({})\n",
    "docs_with_embeddings = collection.count_documents({\"contentVector\": {\"$exists\": True}})\n",
    "docs_without_embeddings = collection.count_documents({\"contentVector\": {\"$exists\": False}})\n",
    "\n",
    "print(f\"üìä Total documents: {total_docs}\")\n",
    "print(f\"‚úÖ Documents with embeddings: {docs_with_embeddings}\")\n",
    "print(f\"‚è≥ Documents without embeddings: {docs_without_embeddings}\")\n",
    "\n",
    "if total_docs == 0:\n",
    "    print(\"\\n‚ö†Ô∏è  Warning: No documents found! Please run scraper first.\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Ready to generate embeddings for {docs_without_embeddings} documents!\")\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "embedder-code"
   },
   "source": [
    "## 4. Embedder Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "embedder-class"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import List, Dict\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pymongo import MongoClient\n",
    "from pymongo.operations import UpdateOne\n",
    "import numpy as np\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class QAEmbedder:\n",
    "    \"\"\"Generates embeddings for Q&A documents and creates vector search index.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the embedder with MongoDB connection and embedding model.\"\"\"\n",
    "        self.mongo_client = None\n",
    "        self.db = None\n",
    "        self.collection = None\n",
    "        self.embedding_model = None\n",
    "        self._setup_mongodb()\n",
    "        self._setup_embedding_model()\n",
    "\n",
    "    def _setup_mongodb(self):\n",
    "        \"\"\"Set up MongoDB connection.\"\"\"\n",
    "        try:\n",
    "            self.mongo_client = MongoClient(MONGODB_URL)\n",
    "            self.db = self.mongo_client[MONGODB_DATABASE]\n",
    "            self.collection = self.db[MONGODB_COLLECTION]\n",
    "            logger.info(\"MongoDB connection established successfully\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to connect to MongoDB: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _setup_embedding_model(self):\n",
    "        \"\"\"Load the embedding model.\"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Loading embedding model: {EMBEDDING_MODEL}\")\n",
    "            self.embedding_model = SentenceTransformer(EMBEDDING_MODEL)\n",
    "\n",
    "            # Verify embedding dimension\n",
    "            test_embedding = self.embedding_model.encode(\"test\", convert_to_numpy=True)\n",
    "            actual_dim = len(test_embedding)\n",
    "\n",
    "            logger.info(f\"Embedding model loaded successfully with dimension: {actual_dim}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load embedding model: {e}\")\n",
    "            raise\n",
    "\n",
    "    def create_combined_text(self, document: Dict) -> str:\n",
    "        \"\"\"Combine topic and question into a single text for embedding.\"\"\"\n",
    "        topic = document.get('topic', '').strip()\n",
    "        question = document.get('question', '').strip()\n",
    "\n",
    "        parts = []\n",
    "        if topic:\n",
    "            parts.append(f\"‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: {topic}\")\n",
    "        if question:\n",
    "            parts.append(f\"‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}\")\n",
    "\n",
    "        return \"\\n\".join(parts) if parts else \"\"\n",
    "\n",
    "    def generate_embedding(self, text: str) -> List[float]:\n",
    "        \"\"\"Generate embedding for the given text.\"\"\"\n",
    "        if not text:\n",
    "            return [0.0] * EMBEDDING_DIMENSION\n",
    "\n",
    "        try:\n",
    "            embedding = self.embedding_model.encode(\n",
    "                text,\n",
    "                convert_to_numpy=True,\n",
    "                normalize_embeddings=True\n",
    "            )\n",
    "            return embedding.tolist()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating embedding: {e}\")\n",
    "            return [0.0] * EMBEDDING_DIMENSION\n",
    "\n",
    "    def embed_documents(self, batch_size: int = 32):\n",
    "        \"\"\"Generate embeddings for all documents in the collection.\"\"\"\n",
    "        try:\n",
    "            # Count total documents\n",
    "            total_docs = self.collection.count_documents({})\n",
    "            logger.info(f\"Found {total_docs} documents to process\")\n",
    "\n",
    "            if total_docs == 0:\n",
    "                logger.warning(\"No documents found in collection. Run scraper first.\")\n",
    "                return\n",
    "\n",
    "            # Count documents without embeddings\n",
    "            docs_without_embeddings = self.collection.count_documents({\n",
    "                \"contentVector\": {\"$exists\": False}\n",
    "            })\n",
    "            logger.info(f\"Documents without embeddings: {docs_without_embeddings}\")\n",
    "\n",
    "            if docs_without_embeddings == 0:\n",
    "                logger.info(\"All documents already have embeddings!\")\n",
    "                return\n",
    "\n",
    "            # Process documents in batches\n",
    "            processed = 0\n",
    "            skipped = 0\n",
    "            updated = 0\n",
    "\n",
    "            # Get all documents without embeddings\n",
    "            cursor = self.collection.find({\"contentVector\": {\"$exists\": False}})\n",
    "\n",
    "            batch_docs = []\n",
    "            batch_texts = []\n",
    "            batch_ids = []\n",
    "\n",
    "            for doc in cursor:\n",
    "                combined_text = self.create_combined_text(doc)\n",
    "\n",
    "                if not combined_text:\n",
    "                    logger.warning(f\"Document {doc['thread_id']}: Empty text, skipping\")\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "\n",
    "                batch_docs.append(doc)\n",
    "                batch_texts.append(combined_text)\n",
    "                batch_ids.append(doc['_id'])\n",
    "\n",
    "                # Process batch when it reaches batch_size\n",
    "                if len(batch_texts) >= batch_size:\n",
    "                    updated += self._process_batch(batch_ids, batch_texts)\n",
    "                    processed += len(batch_texts)\n",
    "                    logger.info(f\"Progress: {processed}/{docs_without_embeddings} documents processed\")\n",
    "\n",
    "                    # Clear batch\n",
    "                    batch_docs = []\n",
    "                    batch_texts = []\n",
    "                    batch_ids = []\n",
    "\n",
    "            # Process remaining documents\n",
    "            if batch_texts:\n",
    "                updated += self._process_batch(batch_ids, batch_texts)\n",
    "                processed += len(batch_texts)\n",
    "\n",
    "            logger.info(f\"Embedding completed! Processed: {processed}, Updated: {updated}, Skipped: {skipped}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during embedding process: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _process_batch(self, doc_ids: List, texts: List[str]) -> int:\n",
    "        \"\"\"Process a batch of documents and update with embeddings.\"\"\"\n",
    "        try:\n",
    "            # Generate embeddings for the batch\n",
    "            embeddings = self.embedding_model.encode(\n",
    "                texts,\n",
    "                convert_to_numpy=True,\n",
    "                normalize_embeddings=True,\n",
    "                batch_size=len(texts)\n",
    "            )\n",
    "\n",
    "            # Prepare bulk update operations\n",
    "            operations = []\n",
    "            for doc_id, embedding in zip(doc_ids, embeddings):\n",
    "                operations.append(\n",
    "                    UpdateOne(\n",
    "                        {\"_id\": doc_id},\n",
    "                        {\"$set\": {\"contentVector\": embedding.tolist()}}\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            # Execute bulk update\n",
    "            result = self.collection.bulk_write(operations)\n",
    "            return result.modified_count\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing batch: {e}\")\n",
    "            return 0\n",
    "\n",
    "    def verify_embeddings(self):\n",
    "        \"\"\"Verify that embeddings were created successfully.\"\"\"\n",
    "        try:\n",
    "            total_docs = self.collection.count_documents({})\n",
    "            docs_with_embeddings = self.collection.count_documents({\n",
    "                \"contentVector\": {\"$exists\": True}\n",
    "            })\n",
    "\n",
    "            logger.info(f\"Verification: {docs_with_embeddings}/{total_docs} documents have embeddings\")\n",
    "\n",
    "            if docs_with_embeddings > 0:\n",
    "                # Check a sample document\n",
    "                sample = self.collection.find_one({\"contentVector\": {\"$exists\": True}})\n",
    "                if sample:\n",
    "                    vector_length = len(sample['contentVector'])\n",
    "                    logger.info(f\"Sample embedding dimension: {vector_length}\")\n",
    "\n",
    "            return docs_with_embeddings == total_docs\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during verification: {e}\")\n",
    "            return False\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Clean up resources.\"\"\"\n",
    "        if self.mongo_client:\n",
    "            self.mongo_client.close()\n",
    "            logger.info(\"MongoDB connection closed\")\n",
    "\n",
    "\n",
    "print(\"‚úÖ Embedder class loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run"
   },
   "source": [
    "## 5. ‡∏£‡∏±‡∏ô Embedder\n",
    "\n",
    "‚ö†Ô∏è **‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏**: ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤ 10-30 ‡∏ô‡∏≤‡∏ó‡∏µ ‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run-embedder"
   },
   "outputs": [],
   "source": [
    "embedder = None\n",
    "try:\n",
    "    print(\"üöÄ Starting embedder...\")\n",
    "    print(\"üì• Loading model and processing documents...\\n\")\n",
    "    \n",
    "    embedder = QAEmbedder()\n",
    "    \n",
    "    # Generate embeddings\n",
    "    print(\"\\nü§ñ Generating embeddings...\")\n",
    "    embedder.embed_documents(batch_size=32)\n",
    "    \n",
    "    # Verify embeddings\n",
    "    print(\"\\nüîç Verifying embeddings...\")\n",
    "    success = embedder.verify_embeddings()\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\n‚úÖ All documents have embeddings!\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  Some documents are missing embeddings\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "finally:\n",
    "    if embedder:\n",
    "        embedder.close()\n",
    "        print(\"üîí Resources cleaned up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "index"
   },
   "source": [
    "## 6. ‡∏™‡∏£‡πâ‡∏≤‡∏á Vector Search Index\n",
    "\n",
    "‚ö†Ô∏è **‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç**: Vector Search Index ‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏ô MongoDB Atlas UI ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å API ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î\n",
    "\n",
    "### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Index ‡πÉ‡∏ô MongoDB Atlas:\n",
    "\n",
    "1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà [MongoDB Atlas Console](https://cloud.mongodb.com/)\n",
    "2. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Cluster ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n",
    "3. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà **Search** tab\n",
    "4. ‡∏Ñ‡∏•‡∏¥‡∏Å **Create Search Index**\n",
    "5. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å **JSON Editor**\n",
    "6. ‡∏ß‡∏≤‡∏á configuration ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"mappings\": {\n",
    "    \"dynamic\": true,\n",
    "    \"fields\": {\n",
    "      \"contentVector\": {\n",
    "        \"type\": \"knnVector\",\n",
    "        \"dimensions\": 1024,\n",
    "        \"similarity\": \"cosine\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "7. ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠ index: `vector_index`\n",
    "8. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Database: `agn`\n",
    "9. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Collection: `qa`\n",
    "10. ‡∏Ñ‡∏•‡∏¥‡∏Å **Create Search Index**\n",
    "11. ‡∏£‡∏≠ 5-10 ‡∏ô‡∏≤‡∏ó‡∏µ‡πÉ‡∏´‡πâ index build ‡πÄ‡∏™‡∏£‡πá‡∏à"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "print-index-config"
   },
   "outputs": [],
   "source": [
    "# ‡πÅ‡∏™‡∏î‡∏á configuration ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á Vector Search Index\n",
    "print(\"üìã Vector Search Index Configuration:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Index Name: {VECTOR_INDEX_NAME}\")\n",
    "print(f\"Database: {MONGODB_DATABASE}\")\n",
    "print(f\"Collection: {MONGODB_COLLECTION}\")\n",
    "print(f\"Field: contentVector\")\n",
    "print(f\"Type: knnVector\")\n",
    "print(f\"Dimensions: {EMBEDDING_DIMENSION}\")\n",
    "print(f\"Similarity: cosine\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nJSON Configuration:\")\n",
    "print(\"\"\"{\n",
    "  \"mappings\": {\n",
    "    \"dynamic\": true,\n",
    "    \"fields\": {\n",
    "      \"contentVector\": {\n",
    "        \"type\": \"knnVector\",\n",
    "        \"dimensions\": 1024,\n",
    "        \"similarity\": \"cosine\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\"\"\")\n",
    "print(\"\\n‚ö†Ô∏è  Please create this index manually in MongoDB Atlas UI\")\n",
    "print(\"üìñ See instructions in the cell above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "verify-final"
   },
   "source": [
    "## 7. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "final-verification"
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(MONGODB_URL)\n",
    "db = client[MONGODB_DATABASE]\n",
    "collection = db[MONGODB_COLLECTION]\n",
    "\n",
    "# ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "total_docs = collection.count_documents({})\n",
    "docs_with_embeddings = collection.count_documents({\"contentVector\": {\"$exists\": True}})\n",
    "\n",
    "print(\"üìä Final Statistics:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total documents: {total_docs}\")\n",
    "print(f\"Documents with embeddings: {docs_with_embeddings}\")\n",
    "print(f\"Coverage: {(docs_with_embeddings/total_docs*100):.2f}%\" if total_docs > 0 else \"Coverage: 0%\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏° embedding\n",
    "if docs_with_embeddings > 0:\n",
    "    print(\"\\nüìÑ Sample document with embedding:\")\n",
    "    sample = collection.find_one({\"contentVector\": {\"$exists\": True}})\n",
    "    if sample:\n",
    "        print(f\"  Thread ID: {sample.get('thread_id')}\")\n",
    "        print(f\"  Topic: {sample.get('topic')[:50]}...\" if sample.get('topic') else \"  Topic: N/A\")\n",
    "        print(f\"  Question: {sample.get('question')[:50]}...\" if sample.get('question') else \"  Question: N/A\")\n",
    "        print(f\"  Embedding dimension: {len(sample['contentVector'])}\")\n",
    "        print(f\"  First 5 values: {sample['contentVector'][:5]}\")\n",
    "\n",
    "client.close()\n",
    "\n",
    "if docs_with_embeddings == total_docs and total_docs > 0:\n",
    "    print(\"\\n‚úÖ All documents have embeddings! Ready for API usage.\")\n",
    "    print(\"\\nüìù Next steps:\")\n",
    "    print(\"1. Create Vector Search Index in MongoDB Atlas (see section 6)\")\n",
    "    print(\"2. Run the FastAPI application (app.py) on your local machine or server\")\n",
    "    print(\"3. Test the chat endpoint at http://localhost:8001/chat\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Not all documents have embeddings. Please check for errors above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "notes"
   },
   "source": [
    "## üìù ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏\n",
    "\n",
    "### ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß:\n",
    "1. ‚úÖ ‡∏ó‡∏∏‡∏Å document ‡∏à‡∏∞‡∏°‡∏µ `contentVector` field\n",
    "2. ‚úÖ Embeddings ‡πÄ‡∏õ‡πá‡∏ô array ‡∏Ç‡∏ô‡∏≤‡∏î 1024 dimensions\n",
    "3. ‚úÖ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Vector Search\n",
    "\n",
    "### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ:\n",
    "1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Vector Search Index ‡πÉ‡∏ô MongoDB Atlas UI (‡∏ï‡∏≤‡∏° section 6)\n",
    "2. ‡∏£‡∏±‡∏ô FastAPI application (`app.py`) ‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n",
    "3. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö API endpoint\n",
    "\n",
    "### Tips:\n",
    "- ‡∏ñ‡πâ‡∏≤‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡πÑ‡∏°‡πà‡∏û‡∏≠ ‡∏•‡∏î `batch_size` ‡πÄ‡∏õ‡πá‡∏ô 16 ‡∏´‡∏£‡∏∑‡∏≠ 8\n",
    "- Embeddings ‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥ (‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡πà‡∏≠‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á)\n",
    "- ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏î‡πâ (‡∏à‡∏∞ skip documents ‡∏ó‡∏µ‡πà‡∏°‡∏µ embeddings ‡πÅ‡∏•‡πâ‡∏ß)\n",
    "- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö logs ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤\n",
    "\n",
    "### ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤:\n",
    "- **Out of Memory**: ‡∏•‡∏î batch_size ‡∏•‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 16 ‡∏´‡∏£‡∏∑‡∏≠ 8\n",
    "- **Model download slow**: ‡πÉ‡∏ä‡πâ Colab Pro ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à\n",
    "- **MongoDB connection timeout**: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö URL ‡πÅ‡∏•‡∏∞ network connection"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
